{
  "llm": {
    "provider": "",
    "model": "",
    "temperature": 0.7,
    "max_tokens": 512
  }
}
